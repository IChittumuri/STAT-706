# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod2), df.residual(bmod2), lower.tail = FALSE)
# Binomial model using quadratic term in temp
bmod2 <- glm(cbind(male, female) ~temp + I(temp^2), family="binomial", turtle)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod2), df.residual(bmod2), lower.tail = FALSE)
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
plot(elogit~temp, turtle)
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash")
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
plot(elogit~temp, turtle)
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(faraway)
library(ggplot2)
d %>%
ggplot(aes(x = prop, y = mod1_pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(faraway)
library(ggplot2)
# columns, the total of maales and gemls and the prop
d <- turtle %>%
mutate(total = male + female,
prop = male/total)
d %>% glimpse()
d %>%
ggplot(aes(x = temp, y = prop)) +
geom_point()
# fit a bimonal model
mod_b <- glm(cbind(male, female) ~ temp, data = d, family = binomial)
summary(mod_b) # the temp estimate of 2.2 means is not not an odds at this point so we need to exp
exp(2.2) #gives 9.02 meaning that as th etmep inceases by 1 degrees the odds that its a male inceases by 9.
# notice that th etemp ranger is really small, and it is resonable that 1 degress of temp could cnage the odds by 9
pchisq(deviance(mod_b), df.residual(mod_b), lower.tail = FALSE)
# under the aussmtion tht mod_b correct, the deviance is chi sq distrbtied. so a low p-values invalided that assumatin an that the model is not a good fit.
# the pvalue is .02, meaning that the model is not a good fit, that the assumation that this follows the binomal distrbition is violoates at aplha level 0.05
# this says that somehting is wrong with the model, something doesnt fti
# this is different from comparing two different models, while you can compare two models in bernuli, you cant measue goodness of fit. but you can in binomal bc the deviacne is appx chi qs with the redicual df.
# the predicotions from the model
d$pred_mod_b <- predict(mod_b, d, type = "response")
# make fake data to make the model line more smooth
d_fake_data <- data.frame(temp = seq(27.2, 29.9, length.out = 100))
d_fake_data$pred_mod_b <- predict(mod_b, d_fake_data, type = "response")
# overlay the model with the predctios
d %>%
ggplot(aes(x = temp, y = prop)) +
geom_point() +
# udate the y that we're ploting, saying use this other dataset and use this plot for y
# geom_smooth(method = "glm", method.args = list(family = "quasibinomial")) +
geom_line(data = d_fake_data, aes(y = pred_mod_b), linetype = "longdash")
# the smooth fn is showing the codifenced interfval, tho the term is se. dont us this for infrernece bc you dont know the model
# quaibinamol allows you to have proportions in th eresponse. binoml is a count, eitje r1 or 0 if beruily or cbind for succeses and failures
# say if you have a quadrative, on fake data
test_data <- data.frame(x = rnorm(1000, mean = 10))
test_data$y <- test_data$x^2
# model it, the quad is sign, saying that x is a good prediotr of the model
# however we know that's making th eassumtion that x is linear to y, but we know that it follow s a quadratic distrbtion
lm(y ~ x, data = test_data) %>% summary()
# look at why the deivince is not following the apportabte chi sq distrubtion
# one reaason is if wehave spare data, bs the bernulli does not follow the chi sq distr therfore if we ahve sparce data it's very close to bernumil
# tho we have low counts, we have more than 5 in each of them
# looking at counts per trial
# sparce means that there arent alot of trial, the sparecist data is bernuilli
# here we're saying there were 6 trials at temp 27, def from 1 trial with 30ppl at temp 27. thats what's being taken into account when we talk about sparseiity
d %>%
ggplot(aes(x = total)) +
geom_histogram()
halfnorm(residuals(mod_b, type = "pearson"))
d %>%
ggplot(aes(x = prop, y = mod1_pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
d <- d %>%
mutate(emp_logit = log((male + .5)/ (female = .5))) %>%
mutate(mod1_pred = predict(mod_b, ., type = "response"))
d %>%
ggplot(aes(x = temp,  y = emp_logit)) +
geom_point()
d %>%
ggplot(aes(x = prop, y = mod1_pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
# Plot the model using temp^2
x <- seq(27,30, .1)
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
summary(bmod2)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod2), df.residual(bmod2), lower.tail = FALSE)
# Binomial model using quadratic term in temp
bmod2 <- glm(cbind(male, female) ~temp + I(temp^2), family="binomial", turtle)
# Plot the model using temp^2
x <- seq(27,30, .1)
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
# Binomial model using quadratic term in temp
bmod2 <- glm(cbind(male, female) ~temp + I(temp^2), family="binomial", turtle)
# Plot the model using temp^2
x <- seq(27,30, .1)
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
# Binomial model using quadratic term in temp
bmod2 <- glm(cbind(male, female) ~temp + I(temp^2), family="binomial", turtle)
# Plot the model using temp^2
x <- seq(27,30, .1)
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
summary(bmod2)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
knitr::opts_chunk$set(echo = TRUE)
# Install packages
library(dplyr)
library(faraway)
library(tidyverse)
# Get dataset
data("turtle")
?turtle
summary(turtle)
# Get the proportion of males
turtle$prop_male <- ifelse(turtle$female == 0, 1, (turtle$male)/(turtle$male+turtle$female))
# Plot it against temp
plot(turtle$temp, turtle$prop_male)
# Binomial model
bmod1 <- glm(cbind(male, female) ~ temp, family="binomial", turtle)
# Get temp in .1 increments
x <- seq(27,30, .1)
# Plot the model
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-61.3183 + 2.2110 * x))
summary(bmod1)
#Chi-squared test, p-value
pchisq(deviance(bmod1), df.residual(bmod1), lower.tail = FALSE)
head(turtle)
# Half normal plot
residuals <- residuals(bmod1)
x <- abs(residuals)
labord <- order(x)
x <- sort(x)
i <- order(x)
n <- length(x)
halfnormal_quant <- qnorm((n + 1:n)/(2 * n + 1))
data.frame(
halfnormal_quant = halfnormal_quant,
abs_residuals = x[i]
) %>%
ggplot(aes(x = halfnormal_quant, y = abs_residuals)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = "longdash") +
coord_equal()
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
plot(elogit~temp, turtle)
emplogit(turtle,log((male + 0.5)/(female + 0.5))
# predict function shows the predictions of the model
turtle %>%
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
plot(elogit~temp, turtle)
# predict function shows the predictions of the model
turtle %>%
mutate(pred = predict(bmod1, ., type = "response")) %>%
ggplot(aes(x = prop_male, y = pred)) +
geom_point() + geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
# Binomial model using quadratic term in temp
bmod2 <- glm(cbind(male, female) ~temp + I(temp^2), family="binomial", turtle)
# Plot the model using temp^2
x <- seq(27,30, .1)
plot(prop_male ~ temp, data = turtle, xlim = c(27,30), ylim = c(0,1),
xlab = "Temperature", ylab = "Proportion of Males")
lines(x, ilogit(-677.595 +(45.9173*x)- (.7745 * x^2)))
summary(bmod2)
# Compare models using anova test
anova(bmod2, bmod1, test = "Chisq")
# Checkfor significane using Chi-squared devience test
pchisq(deviance(bmod2), df.residual(bmod2), lower.tail = FALSE)
# Interaction plot
turtle['elogit'] <- with(turtle,log((male + 0.5)/(female + 0.5)))
plot(elogit~temp, turtle)
with(turtle,interaction.plot(temp,male,elogit))
knitr::opts_chunk$set(echo = TRUE)
library(faraway)
library(dplyr)
library(ggplot2)
pima %>% summary()
# Create a factor variable
# This is by specifying the levels you want to use and what you want then to be labeled as
d <- pima %>%
mutate(test = factor(test, levels = c(0, 1), labels = c("neg", "pos")))
d %>%
ggplot(aes(x = insulin, fill = test)) +
geom_histogram(position = "dodge")
# Replace the NA's
# The brackets mean subset,
# The first part of the code calls are the 0's in that variable and the second part turns them into NA's
d$insulin[d$insulin == 0] <- NA
# Another way to do it
# Ifelse -  if 0, make NA, otherwise leave it
d$insulin <- ifelse(d$insulin == 0, NA, d$insulin)
# Cleaner way to do it
# This is using all the columns that’s in between glucose and bmi and applying the ifelse function to it
# The period in the ifelse code represents the columns itself, doing it over each column. saying if the row in the column is 0, replace with NA, otherwise (the other .) leave it
d <- d %>%
mutate_at(vars(glucose:bmi), ~ifelse(. == 0, NA, .))
d %>% summary()
# gapg
d %>%
filter(!is.na(insulin)) %>% #this code takes out the warning
ggplot(aes(x = insulin, fill = test)) +
geom_histogram(position = "dodge", binwidth = 10) #refers to the number of groups it creates
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(faraway)
library(ggplot2)
# Columns, the total of males and females and the proportion of males
d <- turtle %>%
mutate(total = male + female,
prop = male/total)
d %>% glimpse()
d %>%
ggplot(aes(x = temp, y = prop)) +
geom_point()
# Fit a binomial model
mod_b <- glm(cbind(male, female) ~ temp, data = d, family = binomial)
summary(mod_b) # The temp estimate of 2.2 means is not an odds at this point so we need to exp
exp(2.2) # Gives 9.02 meaning that as the temperature increases by 1 degree, the odds that it’s a male increases by 9.
# Notice that the temperature range is really small, and it is reasonable that 1 degree of temperature could change the odds by 9
pchisq(deviance(mod_b), df.residual(mod_b), lower.tail = FALSE)
# Under the assumption that mod_b is correct, the deviance is chi sq distributed. So a low p-values invalidates that assumption and that the model is not a good fit.
# The predications from the model
d$pred_mod_b <- predict(mod_b, d, type = "response")
# Make fake data to make the model line more smooth
d_fake_data <- data.frame(temp = seq(27.2, 29.9, length.out = 100))
d_fake_data$pred_mod_b <- predict(mod_b, d_fake_data, type = "response")
# Overlay the model with the predictions
d %>%
ggplot(aes(x = temp, y = prop)) +
geom_point() +
# update the y that we're plotting, saying use this other dataset and use this plot for y
geom_smooth(method = "glm", method.args = list(family = "quasibinomial")) +
geom_line(data = d_fake_data, aes(y = pred_mod_b), linetype = "longdash")
# Say if you have a quadratic, on fake data
test_data <- data.frame(x = rnorm(1000, mean = 10))
test_data$y <- test_data$x^2
# Model it, the quadratic is significant, saying that x is a good predator of the model
# However we know that's making the assumption that x is linear to y, but we know that it follows a quadratic distribution
lm(y ~ x, data = test_data) %>% summary()
d %>%
ggplot(aes(x = total)) +
geom_histogram()
halfnorm(residuals(mod_b, type = "pearson"))
d <- d %>%
mutate(emp_logit = log((male + .5)/ (female = .5))) %>%
mutate(mod1_pred = predict(mod_b, ., type = "response"))
d %>%
ggplot(aes(x = temp,  y = emp_logit)) +
geom_point()
d %>%
ggplot(aes(x = prop, y = mod1_pred)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
geom_smooth()
d %>%
ggplot(aes(x = temp, y = mod1_pred - prop)) +
geom_point() +
geom_hline(yintercept = 0, linetype = "longdash")
mod_f <- update(mod_b, . ~ . + I(temp^2))
anova(mod_f, mod_b, test = "Chisq")
pchisq(deviance(mod_f), df.residual(mod_f), lower.tail = F)
d %>%
group_by(temp) %>%
summarise(obs_var = var(prop),
exp_p = sum(male)/sum(male + female),
total_items = sum(male + female)) %>%
ungroup() %>%
mutate(exp_var = exp_p*(1-exp_p)/total_items) %>%
ggplot(aes(x = obs_var, y = exp_var)) +
geom_label(aes(label = temp)) +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
coord_equal(xlim = c(0, .03), ylim = c(0, .03))
d_grouped <- d %>%
group_by(temp) %>%
summarise_at(vars(male, female), sum)
mod_h <- glm(cbind(male, female) ~ temp, data = d_grouped, family = binomial)
# glm(cbind(male, female) ~ temp, data = d_grouped, family = quasibinomial) %>% summary()
library(broom)
tidy(mod_h, conf.int = T) %>%
left_join(tidy(mod_h, conf.int = T), by = "term")
bind_rows(
glance(mod_b),
glance(mod_h)
)
pchisq(deviance(mod_b), df.residual(mod_b), lower.tail = FALSE)
pchisq(deviance(mod_h), df.residual(mod_h), lower.tail = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
summary(pima)
mod <- glm(cbind(test, 1 - test) ~ ., data = pima, family = "binomial")
summary(mod)
pchisq(723.45, 759, lower = FALSE)
pima %>% filter(glucose == 99, pregnant ==1 )
d <- rpart::kyphosis
d %>% glimpse
?rpart::kyphosis
summary(d)
# Histograms
d %>%
ggplot(aes(x = Start)) +
geom_histogram()
d %>%
ggplot(aes(x = Age)) +
geom_histogram()
d %>%
ggplot(aes(x = Number)) +
geom_histogram(bins = 10)
d %>%
ggplot(aes(x = Number)) +
geom_histogram()
d %>%
ggplot(aes(x = Number)) +
geom_histogram(binwidth = 1)
d %>%
ggplot(aes(x = Number)) +
geom_histogram(bin = 50)
d %>%
ggplot(aes(x = Number)) +
geom_histogram(bins = 50)
# Univarite graphs
d %>%
ggplot(aes(x = Start, fill = Kyphosis)) +
geom_density(alpha = .4)
# Correlation of the varibales together
d %>%
ggplot(aes(x = Age, y = Number)) +
geom_point() +
geom_smooth(method = 'loess', formula = y~ x)
# Correlation of the varibales together
d %>%
ggplot(aes(x = Age, y = Number)) +
geom_point() +
geom_smooth(method = 'loess', formula = y~ x)
d %>%
ggplot(aes(x = Age, y = Start)) +
geom_point() +
geom_smooth(method = 'loess', formula = y~ x)
d %>%
ggplot(aes(x = Number, y = Start)) +
geom_point() +
geom_smooth(method = 'loess', formula = y~ x)
library(broom)
# binomial model
# instead of typing out all the predictors, you can just use period which will take everything that is not already in the response
mod <- glm(Kyphosis ~ ., data = d, family = binomial)
mod %>%
tidy(conf.int = T, exponentiate = T)
summary(mod)
mod %>%
tidy(conf.int = T, exponentiate = T)
tidy
mod %>%
tidy
mod %>%
tidy()
# This is all on the odds scale
mod %>%
tidy(conf.int = T, exponentiate = T)
mod2 <- step(mod)
tidy(mod2)
# Step function
mod2 <- step(mod)
tidy(mod2)
#
tidy(mod2)
# Add some fitted values to this
d$fitted <- fitted.values(mod)
# Calibration curve
d %>%
ggplot(aes(x = fitted, y = as.numeric(Kyphosis == 'present'))) +
geom_point() +
geom_smooth() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
coord_cartesian(xlim  = c(0,1), y = c(0, 1))
# Add some fitted values to this
# fitted values give you probiilty right off the bat, you'd have to specify you dont want probabiy
# not how the predict function works, which gives you the linear paratmere that you didnt have to transform.
d$fitted <- fitted.values(mod)
# Calibration curve
d %>%
ggplot(aes(x = fitted, y = as.numeric(Kyphosis == 'present'))) +
geom_point() +
geom_smooth() +
geom_abline(slope = 1, intercept = 0, linetype = "longdash") +
coord_cartesian(xlim  = c(0,1), y = c(0, 1))
?faraway::pima
factor(c(0,1,1,0,1), levels = c(1, 0 ), labels = c('pos', 'neg'))
knitr::opts_chunk$set(echo = TRUE)
x <- data.frame(8,4,0,-4,-8,7.8,9,10.2,11,11.7, columns = T)
View(x)
x <- data.frame(8,4,0,-4,-8,7.8,9,10.2,11,11.7, columns = F)
View(x)
x <- data.frame(8,4,0,-4,-8,7.8,9,10.2,11,11.7, nrow(2), ncol(5))
x <- data.frame(8,4,0,-4,-8,7.8,9,10.2,11,11.7, ncol(5), nrow(2))
x <- data.frame(8,4,0,-4,-8,7.8,9,10.2,11,11.7, nrow(2), ncol(5))
x <- data.frame(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(2), ncol(5))
x <- matrix(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(2), ncol(5))
x <- matrix(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(2), ncol(5), bycol)
x <- matrix(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(2), ncol(5), byrow)
x <- matrix(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(2), ncol(5), byrow)
x <- matrix(c(8,4,0,-4,-8,7.8,9,10.2,11,11.7), nrow(5), ncol(2), byrow)
x <- data.frame("X" = c(8, 4, 0, -4, -8), "Y" = c(7.8, 9, 10.2, 11, 11,7))
x <- data.frame(X = c(8, 4, 0, -4, -8), Y = c(7.8, 9, 10.2, 11, 11,7))
x <- matrix(c(8,4,0,-4,-8,7.8,9.0,10.2,11.0,11.7), ncol = 2, nrow = 5, byrow = F)
x <- matrix(c(8,4,0,-4,-8,7.8,9.0,10.2,11.0,11.7), ncol = 2, nrow = 5, byrow = F)
View(x)
lmod <- ln(V2 ~ V1, data = x)
lmod <- ln(V2 ~ V1, x)
lmod <- lm(V2 ~ V1, x)
lmod <- lm(x$V2 ~ x$V1, x)
lmod <- lm(x$V2 ~ x$V1)
lmod <- lm(V2 ~ V1, data = x)
x %>%
lmod <- lm(V2 ~ V1)
x %>%
lmod <- lm(V2 ~ V1)
x <- matrix(c(8,4,0,-4,-8,7.8,9.0,10.2,11.0,11.7), ncol = 2, nrow = 5, byrow = F); x
x %>%
lmod <- lm(V2 ~ V1)
lmod <- lm(V2 ~ V1, data = x)
x <- matrix(c(8,4,0,-4,-8,7.8,9.0,10.2,11.0,11.7), ncol = 2, nrow = 5, byrow = F)
df <- as.data.frame(x)
View(df)
lmod <- lm(V2 ~ V1, data = df)
summary(lmod)
# check
odds_ratio <- exp(-0.69749 * 2); odds_ratio
# check
odds_ratio <- exp(-0.69749 * 2); odds_ratio
# Calcute log(OR) bc CI is calcuated in a linear scale
log_odds_ratio <- log(odds_ratio); log_odds_ratio
# Calcute exp(CI) to get CI in an odds ratio scale
CI_lower <- exp(log_odds_ratio - (1.96 * 0.07760 * 2)); CI_lower
# check
odds_ratio <- exp(-0.69749 * 2); odds_ratio
